{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def read_base_forms(filename):\n",
    "    base_forms = defaultdict(set)\n",
    "    with open(filename) as file:\n",
    "        for line in tqdm(file):\n",
    "            columns = line.split(';')\n",
    "            base_form = columns[0].lower()\n",
    "            word = columns[1].lower()\n",
    "            base_forms[word].add(base_form)\n",
    "    return base_forms\n",
    "\n",
    "\n",
    "def read_embeddings(filename):\n",
    "    embeddings = {}\n",
    "    for line in tqdm(open(filename)):\n",
    "        line = line.split()\n",
    "        word = line[0].lower()\n",
    "        vector = np.array(line[1:], dtype=np.float32)\n",
    "        embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    tokenized_text = word_tokenize(text) \n",
    "  \n",
    "    table = str.maketrans('', '', string.punctuation + '–')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('polish'))\n",
    "    \n",
    "    cleared_text = [] \n",
    "    for word in tokenized_text:\n",
    "        word = word.translate(table)\n",
    "        if word and word not in stopwords:\n",
    "            cleared_text.append(word)\n",
    "    return cleared_text\n",
    "\n",
    "\n",
    "def read_synsets(synsets_filename):\n",
    "    with open(synsets_filename) as synsets_file:\n",
    "        synsets = [line.strip() for line in synsets_file]\n",
    "    return synsets\n",
    "\n",
    "\n",
    "def read_definitions(filename):\n",
    "    definitions = defaultdict(list)\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            synset, definition = line.strip().split(maxsplit=1)\n",
    "            definitions[synset] += clear_text(definition)\n",
    "    return definitions\n",
    "\n",
    "\n",
    "def read_relations(filename, synsets):\n",
    "    relative_synsets = defaultdict(set)\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            s1, s2, relation = line.strip().split(maxsplit=2)\n",
    "            synset1 = synsets[int(s1)-1]\n",
    "            synset2 = synsets[int(s2)-1]\n",
    "            relative_synsets[synset1].add(synset2)\n",
    "            relative_synsets[synset2].add(synset1)\n",
    "    return relative_synsets\n",
    "    \n",
    "    \n",
    "def create_lemma_synset_mappings(lemmas_filename, synsets_filename, lexicalunits_filename):\n",
    "    with open(lemmas_filename) as lemmas_file:\n",
    "        lemmas = [line.strip().split(',')[0] for line in lemmas_file]\n",
    "    with open(synsets_filename) as synsets_file:\n",
    "        synsets = [line.strip() for line in synsets_file]\n",
    "    with open(lexicalunits_filename) as lexicalunits_file:\n",
    "        lexicalunits = [line.strip().split() for line in lexicalunits_file]\n",
    "    lemma_synsets_mapping = defaultdict(list)\n",
    "    for lemma_id, synset_id in lexicalunits:\n",
    "        lemma_synsets_mapping[lemmas[int(lemma_id)-1]].append(int(synset_id)-1)\n",
    "    synset_lemmas_mapping = defaultdict(list)\n",
    "    for lemma_id, synset_id in lexicalunits:\n",
    "        synset_lemmas_mapping[synsets[int(synset_id)-1]].append(lemmas[int(lemma_id)-1])\n",
    "    return lemma_synsets_mapping, synset_lemmas_mapping\n",
    "\n",
    "    \n",
    "def calculate_idf(definitions, embeddings, synset_lemmas_mapping):\n",
    "    df = defaultdict(int)\n",
    "    N = len(definitions)\n",
    "    for synset, definition in tqdm(definitions.items()):\n",
    "        terms = set()\n",
    "        for word in definition + synset_lemmas_mapping[synset]:\n",
    "            if word not in embeddings:\n",
    "                continue\n",
    "            if word in terms:\n",
    "                continue\n",
    "            terms.add(word)\n",
    "            df[word] += 1\n",
    "    return {word: np.log(N/df_t) for word, df_t in df.items()}\n",
    "\n",
    "    \n",
    "def calculate_lemma_idf(definitions, lemma_embeddings, synset_lemmas_mapping, base_forms):\n",
    "    df = defaultdict(int)\n",
    "    N = len(definitions)\n",
    "    for synset, definition in tqdm(definitions.items()):\n",
    "        terms = set()\n",
    "        for word in definition + synset_lemmas_mapping[synset]:\n",
    "            for lemma in base_forms.get(word, [word]):\n",
    "                if lemma not in lemma_embeddings:\n",
    "                    continue\n",
    "                if lemma in terms:\n",
    "                    continue\n",
    "                terms.add(lemma)\n",
    "                df[lemma] += 1\n",
    "    return {word: np.log(N/df_t) for word, df_t in df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4811854it [00:16, 297051.99it/s]\n"
     ]
    }
   ],
   "source": [
    "base_forms = read_base_forms('../data/polimorfologik/polimorfologik-2.1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "definitions = read_definitions('data/synset_defs_examples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2123133it [01:28, 24075.97it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = read_embeddings('data/nkjp+wiki-forms-all-100-cbow-hs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1549323it [01:08, 22638.07it/s]\n"
     ]
    }
   ],
   "source": [
    "lemma_embeddings = read_embeddings('data/nkjp+wiki-lemmas-all-100-cbow-hs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemma_synsets_mapping, synset_lemmas_mapping = create_lemma_synset_mappings('data/lemmas.txt', \n",
    "                                                                            'data/synsets.txt', \n",
    "                                                                            'data/lexicalunits.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346566/346566 [00:17<00:00, 19866.55it/s]\n"
     ]
    }
   ],
   "source": [
    "idf = calculate_idf(definitions, embeddings, synset_lemmas_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346566/346566 [00:31<00:00, 10873.62it/s]\n"
     ]
    }
   ],
   "source": [
    "lemma_idf = calculate_lemma_idf(definitions, lemma_embeddings, synset_lemmas_mapping, base_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets = read_synsets('data/synsets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_synsets = read_relations('data/synset_rels.txt', synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_word_embedding(matrix, i, word, embeddings, lemma_embeddings, idf, lemma_idf, base_forms, multiplier=1.0):\n",
    "    if word in embeddings:\n",
    "        matrix[i] += multiplier * embeddings[word] * idf[word]\n",
    "    else:\n",
    "        for lemma in base_forms.get(word, [word]):\n",
    "            if lemma in lemma_embeddings:\n",
    "                matrix[i] += multiplier * lemma_embeddings[lemma] * lemma_idf[lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346537/346537 [00:39<00:00, 8847.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from numpy import savez_compressed\n",
    "\n",
    "counter = 0\n",
    "synsets_matrix = np.zeros((len(synsets), len(next(iter(embeddings.values())))))\n",
    "for i, synset in enumerate(tqdm(synsets)):\n",
    "#     for s in [synset] + list(relative_synsets[synset]):\n",
    "#         for word in definitions[s] + synset_lemmas_mapping[s]:\n",
    "#             try:\n",
    "#                 add_word_embedding(synsets_matrix, i, word, embeddings, lemma_embeddings, \n",
    "#                                    idf, lemma_idf, base_forms)\n",
    "#             except KeyError:\n",
    "#                 counter += 1\n",
    "    for word in definitions[synset] + synset_lemmas_mapping[synset]:\n",
    "        add_word_embedding(synsets_matrix, i, word, embeddings, lemma_embeddings, \n",
    "                           idf, lemma_idf, base_forms)\n",
    "    for s in relative_synsets[synset]:\n",
    "        for word in synset_lemmas_mapping[s]:\n",
    "            add_word_embedding(synsets_matrix, i, word, embeddings, lemma_embeddings, \n",
    "                               idf, lemma_idf, base_forms)\n",
    "print(counter)\n",
    "synset_norms = np.linalg.norm(synsets_matrix, axis=1)[:, None]\n",
    "synset_norms[synset_norms == 0] = 0.0000001\n",
    "synsets_matrix = synsets_matrix / synset_norms\n",
    "savez_compressed('synsets_matrix.npz', synsets_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    important_word_ids = []\n",
    "    text = text.lower().split()\n",
    "    punctuation = string.punctuation + '–'\n",
    "    stopwords = set(nltk.corpus.stopwords.words('polish'))\n",
    "    important_words = [] \n",
    "    for i, word in enumerate(text):\n",
    "        word = word.strip(punctuation)\n",
    "        if word and word not in stopwords:\n",
    "            important_words.append(word)\n",
    "            important_word_ids.append(i)\n",
    "    return important_words, important_word_ids\n",
    "\n",
    "\n",
    "def calculate_embedding(i, important_words, embeddings, lemma_embeddings, idf, lemma_idf, k=5):\n",
    "    start = max(i - k, 0)\n",
    "    end = i + k\n",
    "    context = important_words[start:i] + important_words[i+1:end]\n",
    "    embedding = np.zeros(len(next(iter(embeddings.values()))))\n",
    "    counter = 0\n",
    "    for word in context:\n",
    "        try:\n",
    "            if word in embeddings:\n",
    "                embedding += embeddings[word] * idf[word]\n",
    "            else:\n",
    "                for lemma in base_forms.get(word, [word]):\n",
    "                    if lemma in lemma_embeddings:\n",
    "                        embedding += lemma_embeddings[lemma] * lemma_idf[lemma]\n",
    "        except KeyError:\n",
    "            counter += 1\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def disambiguate(text, lemma_synsets_mapping, synsets, base_forms, synsets_matrix, \n",
    "                 embeddings, lemma_embeddings, idf, lemma_idf, k=5):\n",
    "    original_text = text\n",
    "    splitted_original_text = text.split()\n",
    "    important_words, important_word_indices = clear_text(original_text)\n",
    "    disambiguation_results = {}\n",
    "    for word, i in zip(important_words, important_word_indices):\n",
    "        senses = []\n",
    "        for lemma in base_forms.get(word, [word]):\n",
    "            senses += lemma_synsets_mapping[lemma]\n",
    "        if len(senses) > 1:\n",
    "            embedding = calculate_embedding(i, important_words, embeddings, lemma_embeddings,\n",
    "                                            idf, lemma_idf, k)\n",
    "            best_sense = find_best_sense(synsets_matrix, senses, embedding)\n",
    "            disambiguation_results[i] = synsets[best_sense]\n",
    "\n",
    "    for i, synset in disambiguation_results.items():\n",
    "        splitted_original_text[i] += '/{}'.format(synset)     \n",
    "    return ' '.join(splitted_original_text), set(disambiguation_results.values())\n",
    "\n",
    "    \n",
    "def find_best_sense(synsets_matrix, senses, embedding):\n",
    "    distances = cosine_similarity(synsets_matrix[senses], embedding)\n",
    "    best_sense_index = np.argmax(distances)\n",
    "    return senses[best_sense_index]\n",
    "\n",
    "\n",
    "def cosine_similarity(matrix, embedding):\n",
    "    similarity_vector = matrix.dot(embedding.T) / np.linalg.norm(embedding)\n",
    "    return similarity_vector.flatten()\n",
    "\n",
    "\n",
    "def read_human_readable_definitions(filename):\n",
    "    definitions = defaultdict(list)\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            synset, definition = line.strip().split(maxsplit=1)\n",
    "            definitions[synset].append(definition)\n",
    "    return definitions\n",
    "\n",
    "\n",
    "def display_result(text, used_synsets, original_definitions, synset_lemmas_mapping, relative_synsets):\n",
    "    print(text)\n",
    "    print()\n",
    "    for synset in used_synsets:\n",
    "        print('{}({}):'.format(synset, ', '.join(synset_lemmas_mapping[synset])))\n",
    "        for definition in original_definitions[synset]:\n",
    "            print('- {}'.format(definition))\n",
    "        print('Relative synsets: {}'.format(', '.join(['({})'.format(', '.join(synset_lemmas_mapping[s])) \\\n",
    "                                                       for s in relative_synsets[synset]])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_definitions = read_human_readable_definitions('data/synset_defs_examples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import load, savez_compressed\n",
    "synsets_matrix = load('synsets_matrix.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wpisz tekst do zdezambiguowania:\n",
      "pociąg towarowy\n",
      "pociąg/s7294 towarowy/s422837\n",
      "\n",
      "s422837(towarowy):\n",
      "- \"taki, który służy do transportu towarów, jest tak skonstruowany, by móc uczestniczyć w transporcie towarów; np. dworzec **towarowy**, rampa **towarowa**.\"\n",
      "Relative synsets: (budowa, struktura), (conveyance, transferral, transfer, transport, transportation), (functional), (ciężarowy), (cel, przeznaczenie)\n",
      "\n",
      "s7294(kolej, pociąg):\n",
      "- \"środek lokomocji, połączone lokomotywa i wagony.\"\n",
      "- \"**pociąg**, lokomotywa i wagony.\"\n",
      "- \"Wyszła na dworzec po brata, który przyjechał do niej **koleją**.\"\n",
      "Relative synsets: (pociąg szpitalny), (zespół trakcyjny), (pociąg pocztowy), (tender), (kibel), (ekspresowy, expressowy), (pojazd kolejowy), (lokomotywa), (pociąg towarowy), (wąskotorówka, kolejka wąskotorowa), (pociąg pasażerski), (metro), (pociąg szybki), (skomunikować się), (cug), (kolej ogumiona), (pociąg marszrutowy), (kolej żelazna, kolej, droga żelazna), (autobus szynowy, szynobus), (kolejka metra, pociąg metra), (pośpieszny, pospieszny), (wagon), (ekspres, expres), (przyspieszony, przyśpieszony), (skomunikowanie się), (railroad train, train), (pancerka), (pociąg roboczy)\n",
      "\n",
      "\u001b[33m\u001b[1m------------------------------------------------------------\u001b[30m\u001b[0m\n",
      "Wpisz tekst do zdezambiguowania:\n",
      "niezdrowy pociąg\n",
      "niezdrowy/s9951 pociąg/s3128\n",
      "\n",
      "s9951(niezdrowy):\n",
      "- \"Skąd u ciebie taki **niezdrowy** kaszel?\"\n",
      "- \"Ma **niezdrową** cerę, wygląda, jakby coś jej dolegało.\"\n",
      "- \"mający wygląd lub charakter taki jak u osoby chorej, świadczący o czyjejś chorobie lub złym stanie fizycznym.\"\n",
      "Relative synsets: (gorączkowy), (zropiały), (sickly, sallow), (chorowity), (podkrążony), (niezdrowo), (siny, zsiniały, posiniały), (trupi), (popromienny), (sinawy), (rozogniony, zaogniony), (chorobliwy), (mizerny)\n",
      "\n",
      "s3128(predylekcja, inklinacja, ciągoty, pociąg, skłonność, słabość):\n",
      "- \"Mam **słabość** do blondynek.\"\n",
      "- \"Żona go zostawiła, bo miał ciągoty do alkoholu i innych kobiet.\"\n",
      "- \"**skłonność**, upodobanie.\"\n",
      "- \"Moja matka była aktorką, więc to prawdopodobnie po niej odziedziczyłam **inklinację** do teatru.\"\n",
      "- \"trwałe upodobanie.\"\n",
      "- \"Pedofilia oznacza **pociąg** seksualny do dzieci.\"\n",
      "- \"Zygmunt był wielkim władcą, ale miał **predylekcję** do bratania się ze szlachtą, najczęściej pod wpływem mocniejszych trunków.\"\n",
      "- \"**skłonność** do czegoś.\"\n",
      "- \"**skłonność**, upodobanie, chęć.\"\n",
      "- \"trwała cecha osobowości, zamiłowanie do czegoś, **skłonność** do robienia czegoś.\"\n",
      "- \"cecha człowieka, jego osobowości, polegająca na **skłonności** do robienia czegoś, predyspozycji do czegoś.\"\n",
      "Relative synsets: (kłótliwość, swarliwość), (leaning, propensity, proclivity), (pieściwy), (kompromisowość, ugodowość), (inherent aptitude, instinct), (ekshibicjonizm psychiczny, ekshibicjonizm), (soft spot), (ciężka stopa, ciężka noga), (introspekcjonizm), (żyłka, smykałka, zacięcie), (lepkie ręce), (zgodność), (chętność, ochoczość), (ofiarność), (głowa w chmurach), (tendency, disposition, inclination), (smak, miłość, namiętność, pasja, zainteresowania, zamiłowanie, gust, żywioł, miłośnictwo, amatorstwo, namiętnostka, upodobanie), (ryzykancki), (przechył), (orientacja seksualna, orientacja), (cecha osobowości, cecha charakteru, cecha psychiczna), (sadystyczny), (rozerotyzowany), (ciężka pięść, ciężka ręka, ciężka łapa), (szał, bzik, mania, maniactwo, fioł, fiksacja, obsesja, amok, fiś, hyś, hyź, fiks), (trunkowy), (weakness)\n",
      "\n",
      "\u001b[33m\u001b[1m------------------------------------------------------------\u001b[30m\u001b[0m\n",
      "Wpisz tekst do zdezambiguowania:\n",
      "grzbiet wołu\n",
      "grzbiet/s6463 wołu/s12940\n",
      "\n",
      "s12940(wół, wolec):\n",
      "- \"**wół** - wykastrowany samiec bydła domowego z rodziny parzystokopytnych, trzymany w gospodarstwach i używany przez ludzi przy różnych pracach ze względu na zwoją znaczną wielkość i siłę.\"\n",
      "- \"wykastrowany samiec bydła domowego z rodziny parzystokopytnych, trzymany w gospodarstwach i używany przez ludzi przy różnych pracach ze względu na zwoją znaczną wielkość i siłę.\"\n",
      "Relative synsets: (kastrat, trzebieniec), (steer, bullock), (czaban), (bydlę, bydlak), (bukranion), (ox)\n",
      "\n",
      "s6463(grzbiet):\n",
      "- \"część ciała zwierzęcia.\"\n",
      "Relative synsets: (dorsum, back), (zwierzę), (horseback), (karapaks), (saddle), (kłąb), (shoulder), (część ciała)\n",
      "\n",
      "\u001b[33m\u001b[1m------------------------------------------------------------\u001b[30m\u001b[0m\n",
      "Wpisz tekst do zdezambiguowania:\n",
      "zalesiony grzbiet\n",
      "zalesiony/s237382 grzbiet/s5572\n",
      "\n",
      "s237382(zalesiony, lesisty):\n",
      "- \"taki, na którym jest las, są duże skupiska drzew; porośnięty lasem.\"\n",
      "Relative synsets: (wooded), (lesisto), (teren, krajobraz, okolica, strony), (pokrycie, okrycie), (cecha otoczenia)\n",
      "\n",
      "s5572(wierzchołek, szczyt, kulminacja, grzbiet, wierzchnica):\n",
      "- \"najwyżej wzniesiona część góry, **wierzchołek**.\"\n",
      "- \"najwyżej położona część góry, wzniesienia.\"\n",
      "- \"Ze **szczytu** Śnieżki przy dobrej pogodzie można dojrzeć nawet Wrocław.\"\n",
      "- \"**szczyt** - najwyżej wzniesiona część góry.\"\n",
      "- \"najwyżej wzniesiona część góry.\"\n",
      "- \"Na **grzbiet** Śnieżki prowadzi kilka szlaków turystycznych. najwyżej położona część góry.\"\n",
      "- \"**Wierzchołek** Ślęży przypomina stożek.\"\n",
      "- \"Kościół został zbudowany na północnej **kulminacji** wzniesienia.\"\n",
      "Relative synsets: (Waligóra), (Jaworz), (Rudawiec), (góra), (Wielki Chocz), (Anapurna, Annapurna), (Monte Bianco, Mont Blanc), (Magura), (ośmiotysięcznik), (Mt. Everest, Mount Everest, Everest), (Mercedario), (Nuptse), (Wielki Bukowiec), (Jaworzyna), (Modyń), (Śnieżnik), (Rysianka), (Tupungato), (Okrąglica), (Świnica), (pięciotysięcznik), (Uncompahgre Peak), (Changtzu), (Cubryna), (Turbacz), (Denali, Mt. McKinley, Mount McKinley, McKinley), (korona), (Galan), (czub, szczyt, czubek, wierzchołek), (North Peak), (Groniczki), (Makalu), (Chełmiec), (Mount Garmo, Stalin Peak, Mount Communism, Communism Peak), (Sajama), (Jałowiec), (Mount Shasta, Shasta), (Illampu), (Muztagh, Muztag), (Mount Whitney, Whitney), (wierch), (Mount Adams, Adams), (Gasherbrum), (Barania Góra), (Radunia), (Laudo), (Nacimiento), (Wheeler Peak), (grzbiet), (Obidowa), (Mount Elbert), (Mount Bartle Frere), (Aconcagua), (Pobedy Peak, Pobeda Peak), (Dapsang, Mount Godwin Austen, Godwin Austen, K2), (Lubogoszcz), (El Muerto), (Gosainthan), (Bonete), (Huascaran), (Kamet), (Lhotse), (nunatak), (Nanda Devi), (Mount Tacoma, Mt. Rainier, Mount Rainier, Rainier), (Ślęża), (Szrenica), (Cachi), (Coropuna), (El Libertador), (Beskid), (Czupel), (Nanga Parbat), (Pissis), (Wielka Racza), (Chimborazo), (Kinchinjunga, Kanchanjanga, Mount Kanchenjunga, Kanchenjunga), (Mt. Ararat, Mount Ararat, Ararat), (Mount Sherman, Sherman), (Handies Peak), (Yerupaja), (Grand Teton), (Dhaulagiri), (Mount Kilimanjaro, Kilimanjaro), (Tirich Mir), (Ulugh Muz Tagh, Ulugh Muztagh), (Mount Logan, Logan), (Pike's Peak), (wierzchoł), (Czarna Góra), (Rakaposhi), (Ojos del Salado), (Mount Wilson, Wilson), (Wołek), (Matterhorn), (turnia), (Mount Hubbard, Hubbard), (Kołowrót), (wzniesienie, wyniosłość), (Wielka Sowa), (Mt. Rushmore, Mount Rushmore, Rushmore), (Orlica), (Łomnica), (Samanala, Adam's Peak), (Llullaillaco), (turnica), (mountain peak), (Ancohuma)\n",
      "\n",
      "\u001b[33m\u001b[1m------------------------------------------------------------\u001b[30m\u001b[0m\n",
      "Wpisz tekst do zdezambiguowania:\n",
      "Lubię piec ciasteczka, babeczki i torty.\n",
      "Lubię/s53448 piec/s15228 ciasteczka,/s19201 babeczki/s27084 i torty./s11227\n",
      "\n",
      "s15228(piec):\n",
      "- \"ogrzewać potrawy w piecu lub piekarniku w bardzo nagrzanym powietrzu (160-250 °C); w wyniku tej obróbki termicznej białka oraz zawarta w potrawie skrobia stają się łatwiej przyswajalne dla człowieka, następuje ubytek wody, zaś w zewnętrznej warstwie potrawy powstają związki Maillarda.\"\n",
      "Relative synsets: (opiekać), (wypiekać), (piec się), (poke fun, make fun, rib, jest at, laugh at, blackguard, guy, roast, ridicule), (dopiekać), (zapiekać), (przypiekać, podpiekać), (dopiekać), (podpiekać), (przyrządzać, kucharzyć, przygotowywać), (gotować, pichcić, pitrasić, warzyć), (grillować)\n",
      "\n",
      "s53448(lubić):\n",
      "- \"sprawiać wrażenie, jakby coś lub ktoś miało swoje preferencje lub wymagania, mimo braku wolnej woli; reagować lepiej na określone warunki, niż na inne.\"\n",
      "- \"Kaczka **lubi** być dłużej przytrzymana w piekarniku.\"\n",
      "- \"Te kwiaty **lubią**, jak się je podlewa raz w tygodniu.\"\n",
      "- \"Moje włosy nie **lubią** kosmetyków tej firmy.\"\n",
      "- \"Rottweilery **lubią** być trzymane krótko.\"\n",
      "Relative synsets: (mieć to do siebie, mieć do siebie), (polubić), (love)\n",
      "\n",
      "s27084(babeczka):\n",
      "- \"ciastko pieczone w niewielkiej okrągłej formie.\"\n",
      "Relative synsets: (muffin, muffinka), (scone), (ciastko), (papilotek, papilotka), (cupcake)\n",
      "\n",
      "s19201(ciasteczko):\n",
      "Relative synsets: (sezamek, sezamka), (biscuit, cooky, cookie)\n",
      "\n",
      "s11227(tort):\n",
      "Relative synsets: (torte), (torcik), (tort szwarcwaldzki), (tort Sachera), (tort Dobosa, tort Dobosza), (birthday cake), (ciasto), (pavlova), (pischinger), (bridecake, wedding cake), (spód), (layer cake), (krem)\n",
      "\n",
      "\u001b[33m\u001b[1m------------------------------------------------------------\u001b[30m\u001b[0m\n",
      "Wpisz tekst do zdezambiguowania:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wszystkie nowoczesne przeglądarki pozwalają na włączenie bądź wyłączenie mechanizmu ciasteczek.\n",
      "Wszystkie nowoczesne/s103589 przeglądarki/s26212 pozwalają/s2567 na włączenie/s58421 bądź/s250925 wyłączenie/s100072 mechanizmu/s45692 ciasteczek./s425556\n",
      "\n",
      "s2567(pozwalać):\n",
      "Relative synsets: (fotografować się, zdejmować się), (dopuszczać), (dopuszczać), (narażać), (dozwalać), (omamiać się), (móc, być w stanie, być w mocy), (zanieczyszczać), (clear, pass, authorise, authorize), (umożliwiać)\n",
      "\n",
      "s58421(włączyć):\n",
      "- \"Na nowym osiedlu **włączono** wreszcie wodę i prąd.\"\n",
      "- \"zainicjować podłączenie jakiegoś obiektu, miejsca do mediów użytkowych, do elektryki.\"\n",
      "Relative synsets: (przyłączyć), (zaświecić, zapalić), (join), (odkręcić kurek), (począć, jąć, zacząć, rozpocząć, wszcząć, zainicjować), (incorporate)\n",
      "\n",
      "s100072(wyłączenie):\n",
      "Relative synsets: (przerwanie), (włączenie), (cutoff)\n",
      "\n",
      "s425556(ciasteczko):\n",
      "- \"**Ciasteczka** różnych rodzajów są stosowane najczęściej po logowaniu do utrzymywania sesji.\"\n",
      "- \"Mogą jednak przechowywać inne tymczasowe dane jak stan elementów na stronie, czy historię odwiedzanych poprzednio stron (na danej witrynie).\"\n",
      "- \"mały fragment tekstu, który serwis internetowy wysyła do przeglądarki i który przeglądarka wysyła z powrotem przy następnych wejściach na witrynę.\"\n",
      "Relative synsets: (session cookie), (cookie), (precision cookie), (dane)\n",
      "\n",
      "s103589(nowoczesny):\n",
      "- \"Widzę, że postawiłaś na **nowoczesny** styl w kuchni.\"\n",
      "- \"taki, który jest nowożytny, pochodzi ze współczesności, reprezentuje typ czegoś, który łatwo można zidentyfikować jako nowy, taki, który pojawił się stosunkowo niedawno.\"\n",
      "- \"Kup sobie **nowoczesną** kuchenkę, to pokochasz gotowanie.\"\n",
      "- \"**Nowoczesne** osiedla potrafią być samowystarczalne energetycznie i do tego ekologiczne.\"\n",
      "- \"**Nowoczesne** metody uprawy zbóż niesamowicie zwiększają wydajność.\"\n",
      "- \"**Nowoczesna** muzyka nie jest dla mojego dziadka czymś obcym.\"\n",
      "Relative synsets: (supernowoczesny), (nowożytny), (postindustrialny), (biotechnologiczny), (modern-day, contemporary), (amerykański), (nowocześnie), (nowy), (nietradycyjny)\n",
      "\n",
      "s45692(zasada, klucz, mechanizm, system, filozofia):\n",
      "- \"podstawa funkcjonowania lub konstrukcji czegoś.\"\n",
      "- \"Zdołał zbudować silnik działający na **zasadzie** rozbicia atomu i anihilacji materii.\"\n",
      "- \"**zasada** działania czegoś.\"\n",
      "- \"**zasada** działania czegoś, jego powstawania lub przebiegu.\"\n",
      "- \"**Zasady** gry w GO są bardzo proste.\"\n",
      "- \"**Kluczem** do rozwiązania tego problemu było podzielić go na mniejsze fragmenty i usunąć każdą trudność z osobna.\"\n",
      "- \"**Filozofia** działania tego urządzenia jest naprawdę bardzo prosta do zrozumienia.\"\n",
      "- \"Ustawa reguluje **zasady** ruchu na drogach publicznych oraz w strefach zamieszkania.\"\n",
      "- \"założenie, na którym oparto sposób prowadzenia lub rozstrzygania spraw; **zasada**; sposób podejścia do tematu.\"\n",
      "- \"Socjaliści utopijni podjęli trud zaprojektowania społeczeństwa opartego na **zasadach** kooperacji.\"\n",
      "- \"**zasada** organizacji czegoś, podstawa funkcjonowania lub konstrukcji czegoś.\"\n",
      "Relative synsets: (skojarzeniowy, asocjacyjny, asocjatywny), (nieodnawialny), (naciągowy), (loteria wizowa), (omerta), (jakościowo), (sekurytyzacyjny), (aktualizm, uniformatyzm, uniformitarianizm, aktualizm geologiczny), (jednozmianowy), (paskowy), (tercjowy), (controlling), (defensywnie, obronnie), (wolnokonkurencyjny), (feng shui), (wielordzeniowy), (resorowy), (selektywny), (sposób), (bezprocentowy), (honor system), (reguła Tinbergena), (inwersyjny), (bezpiecznik), (trytonowy), (dobór krewniaczy), (substytucyjny), (rozbierany), (interaktywny), (elektrotermiczny), (polimorfizm), (defensywny), (repetycyjny, repetytywny), (logic), (pętlicowy), (mimośrodowo), (konwersyjny), (dyferencyjny), (metodyka), (ósemkowy, oktalny), (spoils system), (frame, frame of reference), (ekwifinalność), (diatoniczny), (nominatywny), (krzywkowy), (zmianowy), (wsobnie), (fourierowsko), (zasada kompensaty), (szesnastobitowy), (nonowy), (dwuobiegowy), (dwuobwodowy), (numeryczny), (gazodynamiczny), (infradźwiękowy), (zabezpieczenie społeczne), (bezbateryjny), (dopplerowski), (bezstykowy), (ajurwedyczny, ajurwedyjski), (na czas), (dożywotność), (naśladowczy, naśladowniczy), (zasada produktywności), (gra), (po bolońsku), (bezdotykowy), (bezpłomieniowy), (tłoczkowy), (potencjometryczny), (absencyjny), (system walutowy), (dolnoprzepustowy), (hydrostatyczny), (diatonicznie), (analityczny), (strój), (irradiacja), (cy pres doctrine, rule of cy pres, cy pres), (ekonomika, typ gospodarki, gospodarka, system ekonomiczny), (boloński), (mimośrodowy), (zasada rzeczywistości), (hiperbaryczny), (kolektywizm), (partycypacyjny), (rekonstruktor semantyczny), (modalny), (dominantowy), (litowy), (interakcjonistyczny), (system partyjny), (antygrawitacyjny), (keplerowski), (głębokościowy), (generyczny), (bezstykowy), (dynamometryczny), (symulacjonizm), (diatonika), (przechyłowy), (systemiczny), (naśladowczo), (system monetarny, system pieniężny), (naporowy), (obchodny, obchodowy), (niskoprężny), (heksadecymalnie, szesnastkowo), (poligamiczny), (wyparny), (asocjatywny), (system rozgrywek), (matrylinearność, matrylinearny system pokrewieństwa), (przewodowy), (bezprzewodowy), (organon), (spychologia), (zwarciowy), (epigenetyczny), (krążkowy), (alaninowy), (monocentryzm), (antyliteracki), (heksadecymalny, szesnastkowy), (kwartowy), (dziedziczenie), (system of rules, system), (naciskowy, uciskowy), (praktycystyczny), (zasada podczepienia), (czteroprzymiotnikowy), (zasada kompozycyjna), (fourierowski), (akcentuacja, akcentacja), (bezsmarowy), (ciśnieniowy), (yang), (ground rule), (bezprzewodowy), (rule), (soniczny, ultradźwiękowy), (modalny), (metatekstowy), (czterobrygadowy), (jednokrotny), (na okaziciela), (mechanizm Hume'a), (repulsorowy), (bezprocentowo), (po rzymsku), (monogamiczny), (regeneracyjny), (patomechanizm), (przewodowy), (wybiórczy, selektywny), (system instancyjny), (mimesis), (yin), (wsobny), (numerycznie), (spychotechnika), (kotwicowy), (selektywnie), (kanban), (tyrystorowy), (agregacja), (wielokrotny), (rekomendacyjny), (patrylinearność, patrylinearny system pokrewieństwa), (regulation, rule), (nadążny), (pluralizm, wielopartyjność, pluralizm polityczny), (aksjologia), (diadynamiczny), (kwintowy), (working rule, working principle), (policentryzm), (imbusowy), (kapitacyjny), (vocabulary), (balansowy), (inercyjnie), (system penitencjarny), (porządek), (asocjacyjnie, skojarzeniowo), (dynamometryczny), (point system), (komisowy), (nakładkowy), (gambling system), (górnoprzepustowy), (system ubezpieczeń społecznych), (pięcioprzymiotnikowy), (analitycznie), (elektroerozyjny), (chromatyka), (accounting standard, accounting principle), (interaktywnie), (optycznie), (podciśnieniowy), (konsorcyjny), (heterologiczny), (bezdotykowo), (magnetoelektryczny), (wrzutowy), (celowość), (kulombowski), (samowyładowczy), (stosunkowość), (klientelistyczny), (zasada domina, teoria domina), (podbudowa, podwaliny, szkielet, trzon, zrąb, fundament, grunt, filar, podwalina, kościec, baza, korpus, principium, pryncypium, substrat, podstawa), (zasada przyjemności), (wielordzeniowo), (inkwizycyjny), (stycznikowy), (discipline)\n",
      "\n",
      "s250925(to, być):\n",
      "- \"**jest** tożsame z czymś; słowo oznaczające utożsamienie ze sobą obiektów lub okoliczności, używane niekiedy zamiast \"**jest**\", \"**są**\".\"\n",
      "- \"Wielu nie zgadza się z tym, że człowiek **to** małpa.\"\n",
      "- \"Oglądanie telewizji **to** strata czasu.\"\n",
      "Relative synsets: (uchodzić), (zawierać się, mieścić się), (stać się, zostać), (pełnić, sprawować), (padać), (bywać), (uzupełniać, dopełniać), (CZASOWNIK STANOWY), (nazywać się), (stanowić), (zostawać, stawać się), (dowodzić, oznaczać, wskazywać, świadczyć, pokazywać, znaczyć, zaświadczać)\n",
      "\n",
      "s26212(przeglądarka):\n",
      "- \"program komputerowy służący do pobierania i wyświetlania stron internetowych udostępnianych przez serwery WWW, a także odtwarzania plików multimedialnych, często przy użyciu dodatkowych rozszerzeń, zwanych wtyczkami.\"\n",
      "Relative synsets: (web browser, browser), (Netscape), (IE, Explorer, Internet Explorer), (lynx), (Mosaic), (program, program komputerowy), (Konqueror), (Opera)\n",
      "\n",
      "\u001b[33m\u001b[1m------------------------------------------------------------\u001b[30m\u001b[0m\n",
      "Wpisz tekst do zdezambiguowania:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-ef5d9c8cac6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0myellow_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Wpisz tekst do zdezambiguowania:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from highlight import yellow_line\n",
    "\n",
    "print('Wpisz tekst do zdezambiguowania:')\n",
    "x = input()\n",
    "while x:\n",
    "    text, used_synsets = disambiguate(x, lemma_synsets_mapping, synsets, base_forms, synsets_matrix,\n",
    "                                      embeddings, lemma_embeddings, idf, lemma_idf)\n",
    "    display_result(text, used_synsets, original_definitions, synset_lemmas_mapping, relative_synsets)\n",
    "    yellow_line()\n",
    "    print('Wpisz tekst do zdezambiguowania:')\n",
    "    x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
